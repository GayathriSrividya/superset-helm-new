postgres:
  adminUser: "postgres"
  adminPassword: "postgres"
  db_port: 5432
  superset:
    db_name: "superset"
    db_username: "superset"
    db_password: "superset"

replicaCount: 1
oauth_enabled: False

serviceAccount:
  create: false

# adminUser:
#   username: "admin"
#   firstname: "Superset"
#   lastname: "Admin"
#   email: "admin@superset.com"
#   password: "admin123"

oauth:
  enabled: false
  client_id: "client_id"
  client_secret: "client_secret"
  email_whitelist_regex: ""
  whitelist_domain: ""
  user_registration_role: "Gamma"

runAsUser: 0

# Install additional packages and do any other bootstrap configuration in this script
# For production clusters it's recommended to build own image with this step done in CI
bootstrapScript: |
  #!/bin/bash
  rm -rf /var/lib/apt/lists/* && \
  pip install \
    keycloak \
    psycopg2-binary==2.9.1 \
    itsdangerous==2.0.1 \
    elasticsearch-dbapi==0.2.9 \
    flask-oidc==1.3.0 \
    Flask-OpenID==1.3.0 \
    werkzeug==1.0.1 \
    redis==3.5.3 && \
  if [ ! -f ~/bootstrap ]; then echo "Running Superset with uid {{ .Values.runAsUser }}" > ~/bootstrap; fi
## The name of the secret which we will use to generate a superset_config.py file
## Note: this secret must have the key superset_config.py in it and can include other files as well
##
configFromSecret: '{{ template "superset.fullname" . }}-config'

## The name of the secret which we will use to populate env vars in deployed pods
## This can be useful for secret keys, etc.
##
envFromSecret: '{{ template "superset.fullname" . }}-env'
## This can be a list of template strings
envFromSecrets: []

## Extra environment variables that will be passed into pods
##
extraEnv:
  OIDC_OPENID_REALM: 'master'
  # Extend timeout to allow long running queries.
  # GUNICORN_TIMEOUT: 300


   # OAUTH_HOME_DOMAIN: ..
  # # If a whitelist is not set, any address that can use your OAuth2 endpoint will be able to login.
  # #   this includes any random Gmail address if your OAuth2 Web App is set to External.
  # OAUTH_WHITELIST_REGEX: ...

## Extra environment variables to pass as secrets
##
extraSecretEnv: {}
  # MAPBOX_API_KEY: ...
  # # Google API Keys: https://console.cloud.google.com/apis/credentials
  # GOOGLE_KEY: ...
  # GOOGLE_SECRET: ...

extraConfigs: {}
  # datasources-init.yaml: |
  #     databases:
  #     - allow_csv_upload: true
  #       allow_ctas: true
  #       allow_cvas: true
  #       database_name: example-db
  #       extra: "{\r\n    \"metadata_params\": {},\r\n    \"engine_params\": {},\r\n    \"\
  #         metadata_cache_timeout\": {},\r\n    \"schemas_allowed_for_csv_upload\": []\r\n\
  #         }"
  #       sqlalchemy_uri: example://example-db.local
  #       tables: []

keycloak_url: ""
redirect_url: ""
sso_admin_client_secret: ""


extraSecrets:
#  {}
  client_secret.json: |
    {
      "web": {
        "issuer": "{{ .Values.keycloak_url }}/realms/master",
        "auth_uri": "{{ .Values.keycloak_url }}/realms/master/protocol/openid-connect/auth",
        "client_id": "admin-api",
        "client_secret": "{{ .Values.sso_admin_client_secret }}",
        "redirect_uris": [
          "{{ .Values.redirect_url }}/*"
        ],
        "userinfo_uri": "{{ .Values.keycloak_url }}/realms/master/protocol/openid-connect/userinfo",
        "token_uri": "{{ .Values.keycloak_url }}/realms/master/protocol/openid-connect/token",
        "token_introspection_uri": "{{ .Values.keycloak_url }}/realms/master/protocol/openid-connect/token/introspect"
      }
    }
  keycloak_security_manager.py: |
    from flask_appbuilder.security.manager import AUTH_OID
    from superset.security import SupersetSecurityManager
    from flask_oidc import OpenIDConnect
    from flask_appbuilder.security.views import AuthOIDView
    from flask_login import login_user
    from urllib.parse import quote
    from flask_appbuilder.views import expose
    from flask import request, redirect
    import logging
    
    
    class OIDCSecurityManager(SupersetSecurityManager):
    
        def __init__(self, appbuilder):
            super(OIDCSecurityManager, self).__init__(appbuilder)
            if self.auth_type == AUTH_OID:
                self.oid = OpenIDConnect(self.appbuilder.get_app)
            self.authoidview = AuthOIDCView
    
    class AuthOIDCView(AuthOIDView):
    
        @expose('/login/', methods=['GET', 'POST'])
        def login(self, flag=True):
            sm = self.appbuilder.sm
            oidc = sm.oid
            superset_roles = ["Admin", "Alpha", "Gamma", "Public", "granter", "sql_lab"]
            print("--------------------------logging in----------------------------------")
            @self.appbuilder.sm.oid.require_login
            def handle_login():
                user = sm.auth_user_oid(oidc.user_getfield('email'))
                print("--------------------------inside handle login----------------------------------")
                if user is None:
                    info = oidc.user_getinfo(['preferred_username', 'given_name', 'family_name', 'email', 'roles', 'realm_access'])
                    realm_roles = oidc.user_getfield('realm_access')["roles"];              
                    roles = [role for role in superset_roles if role in info.get('roles', [])]
    
                    role_mapping = {"superset-admin": "Admin"}
                    for role in realm_roles:
                        if role in role_mapping:
                            roles.append(role_mapping[role]); 
                    logging.info(roles); 
                    user = sm.add_user(info.get('preferred_username'), info.get('given_name', ''), info.get('family_name', ''),
                                       info.get('email'), [sm.find_role(role) for role in roles])
    
                login_user(user, remember=False, force=True)
                return redirect("/dashboard/list/")
    
            return handle_login()
    
        @expose('/logout/', methods=['GET', 'POST'])
        def logout(self):
            oidc = self.appbuilder.sm.oid
    
            oidc.logout()
            super(AuthOIDCView, self).logout()
            redirect_url = request.url_root.strip('/')
            # redirect_url = request.url_root.strip('/') + self.appbuilder.get_url_for_login
    
            return redirect(
                oidc.client_secrets.get('issuer') + '/protocol/openid-connect/logout?redirect_uri=' + quote(redirect_url))    
    
extraVolumes: []
extraVolumeMounts: []

# A dictionary of overrides to append at the end of superset_config.py - the name does not matter
# WARNING: the order is not guaranteed
configOverrides:
  enable_feature_flags: |
    FEATURE_FLAGS = {
      "DASHBOARD_NATIVE_FILTERS": True,
      "DASHBOARD_CROSS_FILTERS": True,
      "DASHBOARD_NATIVE_FILTERS_SET": True,
      "ENABLE_TEMPLATE_PROCESSING": True
    }
  data_cache_config: |
    from superset.superset_typing import CacheConfig
    DATA_CACHE_CONFIG: CacheConfig = {
      'CACHE_TYPE': 'RedisCache',
      'CACHE_DEFAULT_TIMEOUT': 600,
      'CACHE_KEY_PREFIX': 'data_',
      'CACHE_REDIS_URL': 'redis://{{ template "superset.fullname" . }}-redis-headless.{{ .Release.Namespace }}.svc.cluster.local:6379/1'
    }
  filter_cache_config: |
    FILTER_STATE_CACHE_CONFIG: CacheConfig = {
      'CACHE_TYPE': 'RedisCache',
      'CACHE_DEFAULT_TIMEOUT': 600,
      'CACHE_KEY_PREFIX': 'filter_',
      'CACHE_REDIS_URL': 'redis://{{ template "superset.fullname" . }}-redis-headless.{{ .Release.Namespace }}.svc.cluster.local:6379/1',
      # should the timeout be reset when retrieving a cached value
      "REFRESH_TIMEOUT_ON_RETRIEVAL": True
    }
  explore_form_data_cache_config: |
    EXPLORE_FORM_DATA_CACHE_CONFIG: CacheConfig = {
        'CACHE_TYPE': 'RedisCache',
        'CACHE_DEFAULT_TIMEOUT': 600,
        'CACHE_KEY_PREFIX': 'explore_',
        'CACHE_REDIS_URL': 'redis://{{ template "superset.fullname" . }}-redis-headless.{{ .Release.Namespace }}.svc.cluster.local:6379/1',
        "REFRESH_TIMEOUT_ON_RETRIEVAL": True
    }
  sql_alchemy_config: |
    SQLALCHEMY_DATABASE_URI = 'postgresql://{{ tpl .Values.postgres.superset.db_username . }}:{{ tpl .Values.postgres.superset.db_password . }}@{{ template "superset.fullname" . }}-postgresql-hl.{{ .Release.Namespace }}.svc.cluster.local:5432/{{ tpl .Values.postgres.superset.db_name . }}'
    SQLALCHEMY_TRACK_MODIFICATIONS = True
    SECRET_KEY = 'thisISaSECRET_1234'

configOverridesFiles: {}

# configMountPath: "/etc/superset"
configMountPath: "/app/pythonpath"

extraConfigMountPath: "/app/configs"

image:
  # repository: amancevice/superset
  # tag: edge
  repository: apache/superset
  tag: 2.0.0
  pullPolicy: Always

imagePullSecrets: []


service:
  type: LoadBalancer
  port: 8088
  annotations: {}

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    ## Extend timeout to allow long running queries.
    # nginx.ingress.kubernetes.io/proxy-connect-timeout: "300"
    # nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    # nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
  path: /
  pathType: ImplementationSpecific
  hosts:
    - chart-example.local
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

##
## Superset node configuration
supersetNode:
  command:
    - "/bin/sh"
    - "-c"
    - ". {{ .Values.configMountPath }}/superset_bootstrap.sh; /usr/bin/run-server.sh"
  connections:
    redis_host: '{{ template "superset.fullname" . }}-redis-headless'
    redis_port: "6379"
    db_host: '{{ template "superset.fullname" . }}-postgresql-hl.{{ .Release.Namespace }}.svc.cluster.local'
    db_port: "{{ .Values.postgres.db_port }}"
    db_user: "{{ .Values.postgres.superset.db_username }}"
    db_pass: "{{ .Values.postgres.superset.db_password }}"
    db_name: "{{ .Values.postgres.superset.db_name }}"
  forceReload: false # If true, forces deployment to reload on each upgrade
  # initContainers:
  #   - name: wait-for-postgres
  #     image: busybox:latest
  #     imagePullPolicy: IfNotPresent
  #     envFrom:
  #       - secretRef:
  #           name: '{{ tpl .Values.envFromSecret . }}'
  #     command: [ "/bin/sh", "-c", "until nc -zv $DB_HOST $DB_PORT -w1; do echo 'waiting for db'; sleep 1; done" ]
  ## Annotations to be added to supersetNode deployment
  deploymentAnnotations: {}
  ## Annotations to be added to supersetNode pods
  podAnnotations: {}

##
## Init job configuration
init:
  # Configure resources
  # Warning: fab command consumes a lot of ram and can
  # cause the process to be killed due to OOM if it exceeds limit
  resources: {}
    # limits:
    #   cpu:
    #   memory:
    # requests:
    #   cpu:
    #   memory:
  command:
    - "/bin/sh"
    - "-c"
    - ". {{ .Values.configMountPath }}/superset_bootstrap.sh; . {{ .Values.configMountPath }}/superset_init.sh"
  enabled: true
  createAdmin: false
  adminUser:
    username: "admin"
    firstname: "Superset"
    lastname: "Admin"
    email: "admin@superset.com"
    password: "admin"
  # initContainers:
  #   - name: wait-for-postgres
  #     image: busybox:latest
  #     imagePullPolicy: IfNotPresent
  #     envFrom:
  #       - secretRef:
  #           name: '{{ tpl .Values.envFromSecret . }}'
  #     command: [ "/bin/sh", "-c", "until nc -zv $DB_HOST $DB_PORT -w1; do echo 'waiting for db'; sleep 1; done" ]
  initscript: |-
    #!/bin/sh
    echo "Upgrading DB schema..."
    superset db upgrade
    echo "Initializing roles..."
    superset init
    {{ if .Values.init.createAdmin }}
    echo "Creating admin user..."
    superset fab create-admin \
                    --username {{ .Values.init.adminUser.username }} \
                    --firstname {{ .Values.init.adminUser.firstname }} \
                    --lastname {{ .Values.init.adminUser.lastname }} \
                    --email {{ .Values.init.adminUser.email }} \
                    --password {{ .Values.init.adminUser.password }} \
                    || true
    {{ end }}
    if [ -f "{{ .Values.extraConfigMountPath }}/import_datasources.yaml" ]; then
      echo "Importing database connections.... "
      superset import_datasources -p {{ .Values.extraConfigMountPath }}/import_datasources.yaml
    fi

## Configuration values for the Redis dependency.
## ref: https://github.com/kubernetes/charts/blob/master/stable/redis/README.md
redis:
  ##
  ## Use the redis chart dependency.
  ## Set to false if bringing your own redis.
  enabled: false
  usePassword: false
  ##
  ## If you are bringing your own redis, you can set the host in redisHost.
  ## redisHost:
  ##
  ## Redis password
  ##
  ## password: superset
  ##
  ## Master configuration
  master:
    ##
    ## Image configuration
    # image:
      ##
      ## docker registry secret names (list)
      # pullSecrets: nil
    ##
    ## Configure persistance
    persistence:
      ##
      ## Use a PVC to persist data.
      enabled: false
      ##
      ## Persistant class
      # storageClass: classname
      ##
      ## Access mode:
      accessModes:
      - ReadWriteOnce
  replica:
    replicaCount: 1
  ##
  ## Disable cluster management by default.
  cluster:
    enabled: false

##
## Configuration values for the postgresql dependency.
## ref: https://github.com/kubernetes/charts/blob/master/stable/postgresql/README.md
postgresql:
  enabled: true
  ##
  ## Use the PostgreSQL chart dependency.
  ## Set to false if bringing your own PostgreSQL.
  auth:
    ## @param auth.enablePostgresUser Assign a password to the "postgres" admin user. Otherwise, remote access will be blocked for this user
    ##
    enablePostgresUser: true
    ## @param auth.postgresPassword Password for the "postgres" admin user. Ignored if `auth.existingSecret` with key `postgres-password` is provided
    ##
    postgresPassword: "postgres"
    ## @param auth.username Name for a custom user to create
    ##
    username: "superset"
    ## @param auth.password Password for the custom user to create. Ignored if `auth.existingSecret` with key `password` is provided
    ##
    password: "superset"
    ## @param auth.database Name for a custom database to create
    ##
    database: "superset"

  service:
    ## @param readReplicas.service.type Kubernetes Service type
    ##
    type: ClusterIP
    ## @param readReplicas.service.ports.postgresql PostgreSQL service port
    ##
    ports:
      postgresql: 5432

  ##
  ## Persistent Volume Storage configuration.
  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes
  persistence:
    ##
    ## Enable PostgreSQL persistence using Persistent Volume Claims.
    enabled: false
    ##
    ## Persistant class
    # storageClass: classname
    ##
    ## Access modes:
    accessModes:
      - ReadWriteOnce

  # nodeSelector: {}

  # tolerations: []

  # affinity: {}